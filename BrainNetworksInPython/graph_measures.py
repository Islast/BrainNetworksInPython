import numpy as np
import networkx as nx
# ==================== Nodal methods =======================


def calc_nodal_partition(G):
    '''
    Returns nodal_partition, module_partition

    where nodal_partition represents a nodal partition of graph G generated by
    the community module as a dictionary of node: module pairs.
    module_partition represents the same partition as a dictionary of
    module: [list of nodes] pairs.


    Note that this is a time intensive process and it is also
    non-deterministic, so for consistency and speed it's best
    to hold on to your partition.
    '''
    import community
    # Make sure the edges are binarized
    for u, v, d in G.edges(data=True):
        if d.get('weight', 1) != 1:
            raise ValueError("G should be a binary graph")
    # Now calculate the best partition
    nodal_partition = community.best_partition(G)

    # Reverse the dictionary to record a list of nodes per module, rather than
    # module per node
    module_partition = {}
    for n, m in nodal_partition.items():
        try:
            module_partition[m].append(n)
        except KeyError:
            module_partition[m] = [n]

    return nodal_partition, module_partition


def participation_coefficient(G, module_partition):
    '''
    Computes the participation coefficient of nodes of G with partition
    defined by module_partition.
    (Guimera et al. 2005).

    - G is a networkx graph
    - module_partition is a dictionary mapping community names to lists of
     nodes in G

    Returns a dictionary mapping the nodes of G to their participation
    coefficient under module_partition.
    '''
    # Initialise dictionary for the participation coefficients
    pc_dict = {}

    # Print a little note to the screen because it can take a long
    # time to run this code
    print('        Calculating participation coefficient -\
           may take a little while')

    # Loop over modules to calculate participation coefficient for each node
    for m in module_partition.keys():
        # Create module subgraph
        M = G.subgraph(set(module_partition[m]))
        for v in M.nodes:
            # Calculate the degree for v
            degree = nx.degree(G=G, nbunch=v)

            # Calculate the number of intramodule edges
            wm_edges = float(nx.degree(G=M, nbunch=v))

            # The participation coeficient is 1 - the square of
            # the ratio of the within module degree and the total degree
            pc = 1 - ((float(wm_edges) / float(degree))**2)

            pc_dict[v] = pc

    return pc_dict


def z_score(G, module_partition):
    '''
    FILL

    - G is a networkx graph
    - module_partition is a dictionary mapping community names to lists of
     nodes in G

    Returns a dictionary mapping the nodes of G to their z-score under
    module_partition.
    '''
    # Initialise dictionary for the z-scores
    z_score = {}

    # Loop over modules to calculate z-score for each node
    for m in module_partition.keys():
        # Create module subgraph
        M = G.subgraph(set(module_partition[m]))
        # Calculate relevant module statistics
        M_degrees = list(dict(M.degree()).values())
        M_degree = np.mean(M_degrees)
        M_std = np.std(M_degrees)
        for v in M.nodes:
            # Calculate the number of intramodule edges
            wm_edges = float(nx.degree(G=M, nbunch=v))
            # Calculate z score as the intramodule degree of v
            # minus the mean intramodule degree, all divided by
            # the standard deviation of intramodule degree
            if M_std != 0:
                zs = (wm_edges - M_degree)/M_std
            else:
                # If M_std is 0, then all M_degrees must be equal.
                # It follows that the intramodule degree of v must equal
                # the mean intramodule degree.
                # It is therefore valid to assign a 0 value to the z-score
                zs = 0
            z_score[v] = zs

    return z_score


def shortest_path(G):
    '''
    Returns a dictionary mapping a node v to the average length of the shortest
    from v to other nodes in G. Not that in this case "length" means the number
    of edges in this path, and not the euclidean distance.

    G is a connected graph
    '''
    shortestpl_dict = {}
    for node in G.nodes():
        shortestpl_dict[node] = np.average(
            list(nx.shortest_path_length(G, source=node).values()))
    return shortestpl_dict


# =============== anatomical measures ========================


def assign_nodal_distance(G):
    '''
    G is a networkx graph with nodal attribute 'centroids' defined for each
    node. The value of 'centroids' should be the cartesian coordinates of
    each node.

    Using the centroids data, calculates the following

    Edge attributes:
    - euclidean: the euclidean length of each edge

    Node attributes:
    - total_dist: the total length of the incident edges for each node
    - average_dist: the average length of the incident edges for each node

    Returns G with modified node and edge attributes
    '''
    from scipy.spatial import distance
    for i, node in enumerate(G.nodes()):
        # Loop through the edges connecting to this node
        # Note that "node1" is equal to "node"
        for node1, node2 in G.edges(nbunch=[node]):

            # Calculate the euclidean distance for this edge
            cent1 = G.node[node1]['centroids']
            cent2 = G.node[node2]['centroids']

            dist = distance.euclidean(cent1, cent2)

            # And assign this value to the edge
            G.adj[node1][node2]['euclidean'] = dist

        # Create two nodal attributes (average distance and
        # total distance) by summarizing the euclidean distance
        # for all edges which connect to the node
        euc_list = [G.adj[m][n]['euclidean'] for m, n in G.edges(nbunch=node)]

        G.node[node]['average_dist'] = np.mean(euc_list)
        G.node[node]['total_dist'] = np.sum(euc_list)
    return G


def assign_interhem(G):
    '''
    An edge is considered interhemispheric if the x coordinates of its nodes
    have different signs.
    Calculates the following edge and node attributes:

    Edge attributes:
    - interhem: 1 if the edge is interhemispheric, 0 otherwise.

    Node attributes:
    - interhem: the number of adjacent interhemispheric edges
    - interhem_proportion: the proportion of the adjacent edges that are
        interhemispheric

    G is a networkx graph with an 'x' or a 'centroids' attribute defined for
    each node.

    Returns G with modified node and edge attributes
    '''
    for i, node in enumerate(G.nodes()):
        for node1, node2 in G.edges(nbunch=[node]):
            # Determine whether this edge is interhemispheric
            # by multiplying the x values.
            try:
                x1 = G.node[node1]['x']
                x2 = G.node[node2]['x']
            except KeyError:
                x1 = G.node[node1]['centroids'][0]
                x2 = G.node[node2]['centroids'][0]

            # Determine whether this edge is interhemispheric
            # by multiplying the x values.
            if x1*x2 > 0:
                G.adj[node1][node2]['interhem'] = 0
            else:
                G.adj[node1][node2]['interhem'] = 1

        # Create an interhem nodal attribute by getting the average
        # of the interhem values for all edges which connect to the node
        interhem_list = [G.adj[m][n]['interhem']
                         for m, n in G.edges(nbunch=node)]
        G.node[node]['interhem'] = sum(interhem_list)
        G.node[node]['interhem_proportion'] = np.mean(interhem_list)
    return G


# ============= Global measures =============


def calc_modularity(G, nodal_partition):
    '''
    Returns the network modularity of G under the
    modules defined by nodal_partition.

    G is a graph and nodal_partition is a partition
    of G indexed by node
    '''
    import community
    return community.modularity(nodal_partition, G)


def rich_club(G):
    return nx.rich_club_coefficient(G, normalized=False)


# ================= Small World methods ============================


def small_world_sigma(tupleG, tupleR):
    '''
    Calculate the small coefficient of graph G relative
    to graph R where tupleG and tupleR are the values
    (average_clustering, average_shortest_path_length)
    of G and R respectively.
    '''
    Cg, Lg = tupleG
    Cr, Lr = tupleR
    return ((Cg/Cr)/(Lg/Lr))


def small_coefficient(G, R):
    '''
    Calculate the small coefficient of G relative to R.
    '''
    return small_world_sigma((nx.average_clustering(G),
                              nx.average_shortest_path_length(G)),
                             (nx.average_clustering(R),
                              nx.average_shortest_path_length(R)))


# ============ Calculate Global Measures En Masse ================


def calculate_global_measures(G,
                              partition=None,
                              existing_global_measures=None):
    '''
    Calculate global measures including FILL for a single graph G
    If a dictionary mapping nodes to modules is passed to partition
    will also calculate the modularity of G under this partition.

    If a dictionary, d, is passed to existin_global_measures, will
    calculate any measures not already keyed in d.
    '''
    # ==== MEASURES ====================
    if existing_global_measures is not None:
        global_measures = existing_global_measures
    else:
        global_measures = {}

    # ---- Clustering coefficient ------
    if 'average_clustering' not in global_measures:
        global_measures['average_clustering'] = (
            nx.average_clustering(G))

    # ---- Shortest path length --------
    if 'average_shortest_path_length' not in global_measures:
        global_measures['average_shortest_path_length'] = (
            nx.average_shortest_path_length(G))

    # ---- Assortativity ---------------
    if 'assortativity' not in global_measures:
        global_measures['assortativity'] = (
            np.mean(nx.degree_assortativity_coefficient(G)))

    # ---- Modularity ------------------
    if partition is not None and 'modularity' not in global_measures:
        global_measures['modularity'] = (
            calc_modularity(G, partition))

    #  ---- Efficiency ------------------
    if 'efficiency' not in global_measures:
        global_measures['efficiency'] = (
            nx.global_efficiency(G))

    return global_measures
