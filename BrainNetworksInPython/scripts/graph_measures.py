import numpy as np
import networkx as nx
import make_graphs as mkg
# ==================== Nodal methods =======================


def calc_nodal_partition(G):
    '''
    Returns a nodal partition of graph G generated by the community
    module.

    Note that this is a time intensive process and it is also
    non-deterministic, so for consistency and speed it's best
    to save a partition.
    '''
    import community
    # Make sure the edges are binarized
    for u, v, d in G.edges(data=True):
        if d['weight'] != 1:
            raise ValueError("input should be a binary graph")
    # Now calculate the best partition
    nodal_partition = community.best_partition(G)

    return nodal_partition


def participation_coefficient(G, nodal_partition):
    '''
    Computes the participation coefficient of nodes of G with partition
    defined by nodal_partition
    (Guimera et al. 2005).

    - G is a networkx graph
    - nodal_partition is a dictionary mapping community names to lists of
     nodes in G

    Returns a dictionary mapping the nodes of G to their participation
    coefficient under nodal_partition.
    '''
    # Reverse the dictionary because the output of Louvain is "backwards"
    # meaning it saves the module per node, rather than the nodes in each
    # module
    module_partition = {}
    for m, n in zip(nodal_partition.values(), nodal_partition.keys()):
        try:
            module_partition[m].append(n)
        except KeyError:
            module_partition[m] = [n]

    # Initialise dictionary for the participation coefficients
    pc_dict = {}

    # Print a little note to the screen because it can take a long
    # time to run this code
    print('        Calculating participation coefficient -\
           may take a little while')
    # Loop over modules to calculate participation coefficient for each node
    for m in module_partition.keys():
        mod_list = set(module_partition[m])
        for source in mod_list:
            # Calculate the degree for the 'source' node
            degree = nx.degree(G=G, nbunch=source)

            # Calculate the number of intramodule edges
            wm_edges = 0
            for target in mod_list:
                if (source, target) in G.edges():
                    wm_edges += 1

            # The participation coeficient is 1 - the square of
            # the ratio of the within module degree and the total degree
            pc = 1 - ((float(wm_edges) / float(degree))**2)

            pc_dict[source] = pc

    return pc_dict


def calc_modularity(G, nodal_partition):
    '''
    Returns the network modularity of G under the
    modules defined by nodal_partition.

    G is a graph and nodal_partition is a partition
    of G indexed by node
    '''
    import community
    return community.modularity(nodal_partition, G)


def calc_efficiency(G):
    '''
    Returns the global efficiency of G
    '''
    E = 0.0
    for node in G:
        path_length = nx.single_source_shortest_path_length(G, node)
        E += 1.0/sum(path_length.values())
    return E


def assign_nodal_distance(G):
    '''
    G is a networkx graph with nodal attribute 'centroids' defined for each
    node. The value of 'centroids' should be the cartesian coordinates of
    each node.

    Using the centroids data, calculates the following

    Edge attributes:
    - euclidean: the euclidean length of each edge

    Node attributes:
    - total_dist: the total length of the incident edges for each node
    - average_dist: the average length of the incident edges for each node

    Returns G with modified node and edge attributes
    '''
    from scipy.spatial import distance
    for i, node in enumerate(G.nodes()):
        # Loop through the edges connecting to this node
        # Note that "node1" is equal to "node"
        for node1, node2 in G.edges(nbunch=[node]):

            # Calculate the euclidean distance for this edge
            cent1 = G.node[node1]['centroids']
            cent2 = G.node[node2]['centroids']

            dist = distance.euclidean(cent1, cent2)

            # And assign this value to the edge
            G.adj[node1][node2]['euclidean'] = dist

        # Create two nodal attributes (average distance and
        # total distance) by summarizing the euclidean distance
        # for all edges which connect to the node
        euc_list = [G.adj[m][n]['euclidean'] for m, n in G.edges(nbunch=node)]

        G.node[node]['average_dist'] = np.mean(euc_list)
        G.node[node]['total_dist'] = np.sum(euc_list)
    return G


def assign_interhemispheric(G):
    '''
    An edge is considered interhemispheric if the x coordinates of its nodes
    have different signs.
    Calculates the following edge and node attributes:

    Edge attributes:
    - interhem: 1 if the edge is interhemispheric, 0 otherwise.

    Node attributes:
    - interhem: the number of adjacent interhemispheric edges
    - interhem_proportion: the proportion of the adjacent edges that are
        interhemispheric

    G is a networkx graph with an 'x' or a 'centroids' attribute defined for
    each node.

    Returns G with modified node and edge attributes
    '''
    for i, node in enumerate(G.nodes()):
        for node1, node2 in G.edges(nbunch=[node]):
            # Determine whether this edge is interhemispheric
            # by multiplying the x values.
            try:
                x1 = G.node[node1]['x']
                x2 = G.node[node2]['x']
            except KeyError:
                x1 = G.node[node1]['centroids'][0]
                x2 = G.node[node2]['centroids'][0]

            # Determine whether this edge is interhemispheric
            # by multiplying the x values.
            if x1*x2 > 0:
                G.adj[node1][node2]['interhem'] = 0
            else:
                G.adj[node1][node2]['interhem'] = 1

        # Create an interhem nodal attribute by getting the average
        # of the interhem values for all edges which connect to the node
        interhem_list = [G.adj[m][n]['interhem']
                         for m, n in G.edges(nbunch=node)]
        G.node[node]['interhem_proportion'] = np.mean(interhem_list)
    return G


def shortest_path(G):
    '''
    Returns a dictionary mapping a node v to the average length of the shortest
    from v to other nodes in G. Not that in this case "length" means the number
    of edges in this path, and not the euclidean distance.

    G is a connected graph
    '''
    shortestpl_dict_dict = dict(nx.shortest_path_length(G))

    shortestpl_dict = {}

    for node in G.nodes():
        shortestpl_dict[node] = np.average(
                                list(shortestpl_dict_dict[node].values()))
    return shortestpl_dict


def calculate_nodal_measures(G,
                             centroids,
                             aparc_names,
                             nodal_partition=None,
                             names_308_style=True):
    '''
    A function which returns a dictionary of numpy arrays for a graph's
        * degree
        * participation coefficient
        * average distance
        * total distance
        * clustering
        * closeness
        * interhemispheric proportion
        * name
    If you have names in 308 style (as described in Whitaker, Vertes et al
    2016) then you can also add in
        * hemisphere
        * 34_name (Desikan Killiany atlas region)
        * 68_name (Desikan Killiany atlas region with hemisphere)
    '''

    # ==== SET UP ======================
    # If you haven't passed the nodal partition
    # then calculate it here
    if not nodal_partition:
        nodal_partition = calc_nodal_partition(G)

    # ==== MEASURES ====================
    nodal_dict = {}

    # ---- Degree ----------------------
    deg = dict(G.degree()).values()
    nodal_dict['degree'] = list(deg)

    # ---- Closeness -------------------
    closeness = nx.closeness_centrality(G).values()
    nodal_dict['closeness'] = list(closeness)

    # ---- Betweenness -----------------
    betweenness = nx.betweenness_centrality(G).values()
    nodal_dict['betweenness'] = list(betweenness)

    # ---- Shortest path length --------
    L = shortest_path(G).values()
    nodal_dict['shortest_path'] = list(L)

    # ---- Clustering ------------------
    clustering = nx.clustering(G).values()
    nodal_dict['clustering'] = list(clustering)

    # ---- Participation coefficent ----
    # ---- and module assignment -------
    partition, pc_dict = participation_coefficient(G, nodal_partition)
    nodal_dict['module'] = list(partition.values())
    nodal_dict['pc'] = list(pc_dict.values())

    # ---- Euclidean distance and ------
    # ---- interhem proporition --------
    G = assign_nodal_distance(G, centroids)
    average_dist = nx.get_node_attributes(G, 'average_dist').values()
    total_dist = nx.get_node_attributes(G, 'total_dist').values()
    interhem_prop = nx.get_node_attributes(G, 'interhem_proportion').values()

    nodal_dict['average_dist'] = list(average_dist)
    nodal_dict['total_dist'] = list(total_dist)
    nodal_dict['interhem_prop'] = list(interhem_prop)

    # ---- Names -----------------------
    G = mkg.assign_node_names(G, aparc_names, names_308_style=names_308_style)
    name = nx.get_node_attributes(G, 'name').values()
    nodal_dict['name'] = list(name)
    if names_308_style:
        name_34 = nx.get_node_attributes(G, 'name_34').values()
        name_68 = nx.get_node_attributes(G, 'name_68').values()
        hemi = nx.get_node_attributes(G, 'hemi').values()
        nodal_dict['name_34'] = list(name_34)
        nodal_dict['name_68'] = list(name_68)
        nodal_dict['hemi'] = list(hemi)

    return G, nodal_dict
